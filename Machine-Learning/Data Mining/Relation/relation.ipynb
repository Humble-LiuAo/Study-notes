{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\"><h1>统计学习方法课后作业</h1></div>\n",
    "<div class=\"alert alert-block alert-success\"> <h3>作者：学号:Z21160043 姓名:刘奥</h3></div> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read data from file 'simple.csv'. One line is a transaction. Get a list of all transactions.\n",
    "\n",
    "Hint: Dimensionality reduction\n",
    "<blockquote>\n",
    "from itertools import chain<br>\n",
    "one = list(chain.from_iterable(data))\n",
    "</blockquote>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bread, Butter\n",
      "Bread, Jelly\n",
      "Bread, Milk, Butter\n",
      "Chips, Milk\n",
      "Bread, Chips\n",
      "Bread, Jelly, Peanut, Butter\n",
      "Bread, Milk\n",
      "Chips, Jelly\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "f = Path('simple.csv')\n",
    "print(f.read_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Bread', 'Butter'},\n",
       " {'Bread', 'Jelly'},\n",
       " {'Bread', 'Butter', 'Milk'},\n",
       " {'Chips', 'Milk'},\n",
       " {'Bread', 'Chips'},\n",
       " {'Bread', 'Butter', 'Jelly', 'Peanut'},\n",
       " {'Bread', 'Milk'},\n",
       " {'Chips', 'Jelly'}]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = [set(line.split(',')) for line in f.read_text().replace(' ','').split('\\n')]\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#set n as the number of dataset\n",
    "n=len(data)\n",
    "n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List all unique items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Bread', 'Butter', 'Chips', 'Jelly', 'Milk', 'Peanut'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from itertools import chain\n",
    "items = set(chain.from_iterable(data))\n",
    "items"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the number of one itemset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def number(itemset):\n",
    "    return sum([itemset.issubset(tran) for tran in data])\n",
    "\n",
    "number({'Bread', 'Butter'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the support of one itemset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.375"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def support(itemset): \n",
    "    return number(itemset)/n\n",
    "\n",
    "support({'Bread', 'Butter'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the confidence of one itemset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def confidence(itemset1, itemset2):\n",
    "    return support(itemset1|itemset2)/support(itemset1)\n",
    "\n",
    "confidence({'Bread'}, {'Butter'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the number of all 1-itemset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'Butter': 3}, {'Bread': 6}, {'Jelly': 3}, {'Peanut': 1}, {'Chips': 3}, {'Milk': 3}]\n"
     ]
    }
   ],
   "source": [
    "itemset_num_1 = [{item:number({item})} for item in items]\n",
    "print(itemset_num_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the support of all 1-itemset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'Butter': 0.375}, {'Bread': 0.75}, {'Jelly': 0.375}, {'Peanut': 0.125}, {'Chips': 0.375}, {'Milk': 0.375}]\n"
     ]
    }
   ],
   "source": [
    "itemset_sup_1 = [{item:support({item})} for item in items]\n",
    "print(itemset_sup_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the confidence of all 1-itemset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Butter->Bread': 1.0},\n",
       " {'Butter->Jelly': 0.3333333333333333},\n",
       " {'Butter->Peanut': 0.3333333333333333},\n",
       " {'Butter->Chips': 0.0},\n",
       " {'Butter->Milk': 0.3333333333333333}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_con_1 = [{f'{item1}->{item2}': confidence({item1}, {item2})} for item1 in items for item2 in items if item1 != item2]\n",
    "item_con_1[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[frozenset({'Butter'}),\n",
       " frozenset({'Bread'}),\n",
       " frozenset({'Jelly'}),\n",
       " frozenset({'Peanut'}),\n",
       " frozenset({'Chips'}),\n",
       " frozenset({'Milk'})]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C1 = [frozenset({item}) for item in items]\n",
    "C1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Apriori Algorithm to calculate the frequent itemset of the data in file 'simple.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[frozenset({'Butter'}),\n",
       "  frozenset({'Bread'}),\n",
       "  frozenset({'Jelly'}),\n",
       "  frozenset({'Chips'}),\n",
       "  frozenset({'Milk'})],\n",
       " [frozenset({'Bread', 'Milk'}),\n",
       "  frozenset({'Bread', 'Butter'}),\n",
       "  frozenset({'Bread', 'Jelly'})]]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigma = 0.2\n",
    "C1 = [frozenset({item}) for item in items]\n",
    "Lk = [[i for i in C1 if support(i)>sigma]]\n",
    "while Lk[-1]!=[]: # L[-1] The last item\n",
    "    Ck = set([ i|j for i in  Lk[-1] for j in Lk[-1] if i != j ])\n",
    "    Lk .append([i for i in Ck if support(i)>sigma])\n",
    "Lk = Lk[:-1]\n",
    "Lk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Another complete way\n",
    "class Aproiri():\n",
    "    def __init__(self,data,sigma,phi):\n",
    "        self.sigma = sigma\n",
    "        self.phi = phi\n",
    "        self.data = data\n",
    "    \n",
    "    def Create_C1(self):\n",
    "        items = set(chain.from_iterable(self.data))\n",
    "        C1 = [frozenset({item}) for item in items]\n",
    "        return C1\n",
    "    \n",
    "    def Cal_Lk(self, Ck):\n",
    "        Lk = [frozenset(itemset) for itemset in Ck if support(itemset) > self.sigma]\n",
    "        Lk_support = [{itemset:support(itemset)} for itemset in Lk]\n",
    "        return Lk, Lk_support\n",
    "    \n",
    "    def Creat_C_kadd1(self,Lk):\n",
    "        Ck = []\n",
    "        for i in range(len(Lk)):\n",
    "            for j in range(i+1,len(Lk)):\n",
    "                if len(Lk[i]-Lk[j])==1:\n",
    "                    if (Lk[i]|Lk[j]) not in Ck:\n",
    "                        Ck.append(frozenset(Lk[i]|Lk[j]))\n",
    "        return Ck\n",
    "    \n",
    "    def apriori(self):\n",
    "        C1 = self.Create_C1()\n",
    "        L1, L1_support = self.Cal_Lk(C1)\n",
    "        k = 1\n",
    "        L_union = []\n",
    "        L_union_support = []\n",
    "        L_union.extend(L1)\n",
    "        L_union_support.extend(L1_support)\n",
    "        while k <= n:\n",
    "            C_kadd1= self.Creat_C_kadd1(L1)\n",
    "            Lk,Lk_support = self.Cal_Lk(C_kadd1)\n",
    "            if Lk == []:\n",
    "                break\n",
    "            L_union.extend(Lk)\n",
    "            L_union_support.extend(Lk_support)\n",
    "            k+=1\n",
    "            L1 = Lk\n",
    "        return L_union, L_union_support\n",
    "    \n",
    "    def association_rules(self, L_union, L_union_support):\n",
    "        rules = []\n",
    "        length = len(L_union)\n",
    "        for i in range(length):\n",
    "            for j in range(i+1,length):\n",
    "                    if L_union[i] < L_union[j]:\n",
    "                        support = L_union_support[j][L_union[j]]\n",
    "                        conf = confidence(L_union[i],L_union[j])\n",
    "                        if conf >= self.phi:\n",
    "                            rule = ({f'{L_union[i]}-->{L_union[j] - L_union[i]}(support:{support})': conf})\n",
    "                            rules.append(rule)\n",
    "        return rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{frozenset({'Butter'}): 0.375},\n",
       " {frozenset({'Bread'}): 0.75},\n",
       " {frozenset({'Jelly'}): 0.375},\n",
       " {frozenset({'Chips'}): 0.375},\n",
       " {frozenset({'Milk'}): 0.375},\n",
       " {frozenset({'Bread', 'Butter'}): 0.375},\n",
       " {frozenset({'Bread', 'Jelly'}): 0.25},\n",
       " {frozenset({'Bread', 'Milk'}): 0.25}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "apro = Aproiri(data,0.2,0.5)\n",
    "L_union, L_union_support = apro.apriori()\n",
    "L_union_support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{\"frozenset({'Butter'})-->frozenset({'Bread'})(support:0.375)\": 1.0},\n",
       " {\"frozenset({'Bread'})-->frozenset({'Butter'})(support:0.375)\": 0.5},\n",
       " {\"frozenset({'Jelly'})-->frozenset({'Bread'})(support:0.25)\": 0.6666666666666666},\n",
       " {\"frozenset({'Milk'})-->frozenset({'Bread'})(support:0.25)\": 0.6666666666666666}]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rules = apro.association_rules(L_union,L_union_support)\n",
    "rules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Apriori Algorithm to calculate the frequent itemset of the data in file 'Market_Basket_Optimisation.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 26.1 ms, sys: 9.71 ms, total: 35.8 ms\n",
      "Wall time: 33.3 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# New data sets redefine variable functions\n",
    "f_Mar = Path('Market_Basket_Optimisation.csv')\n",
    "data = [set(line.split(',')) for line in f_Mar.read_text().strip().split('\\n')]\n",
    "n=len(data)\n",
    "def number(itemset):\n",
    "    return sum([itemset.issubset(tran) for tran in data])\n",
    "def support(itemset): \n",
    "    return number(itemset)/n\n",
    "def confidence(itemset1, itemset2):\n",
    "    return support(itemset1|itemset2)/support(itemset1)\n",
    "items = set(chain.from_iterable(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[frozenset({'pancakes'}),\n",
       "  frozenset({'tomatoes'}),\n",
       "  frozenset({'ground beef'}),\n",
       "  frozenset({'mineral water'}),\n",
       "  frozenset({'spaghetti'}),\n",
       "  frozenset({'low fat yogurt'}),\n",
       "  frozenset({'olive oil'}),\n",
       "  frozenset({'frozen smoothie'}),\n",
       "  frozenset({'eggs'}),\n",
       "  frozenset({'chicken'}),\n",
       "  frozenset({'escalope'}),\n",
       "  frozenset({'cooking oil'}),\n",
       "  frozenset({'whole wheat rice'}),\n",
       "  frozenset({'green tea'}),\n",
       "  frozenset({'turkey'}),\n",
       "  frozenset({'chocolate'}),\n",
       "  frozenset({'french fries'}),\n",
       "  frozenset({'milk'}),\n",
       "  frozenset({'cake'}),\n",
       "  frozenset({'cookies'}),\n",
       "  frozenset({'shrimp'}),\n",
       "  frozenset({'soup'}),\n",
       "  frozenset({'grated cheese'}),\n",
       "  frozenset({'frozen vegetables'}),\n",
       "  frozenset({'burgers'})],\n",
       " [frozenset({'mineral water', 'spaghetti'}),\n",
       "  frozenset({'eggs', 'mineral water'}),\n",
       "  frozenset({'chocolate', 'mineral water'})]]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigma = 0.05\n",
    "C1 = [frozenset({item}) for item in items]\n",
    "Lk = [[i for i in C1 if support(i)>sigma]]\n",
    "while Lk[-1]!=[]:\n",
    "    Ck = set([ i|j for i in  Lk[-1] for j in Lk[-1] if i != j ])\n",
    "    Lk .append([i for i in Ck if support(i)>sigma])\n",
    "Lk = Lk[:-1]\n",
    "Lk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{frozenset({'pancakes'}): 0.09505399280095987},\n",
       " {frozenset({'tomatoes'}): 0.06839088121583789},\n",
       " {frozenset({'ground beef'}): 0.09825356619117451},\n",
       " {frozenset({'mineral water'}): 0.23836821757099053},\n",
       " {frozenset({'spaghetti'}): 0.17411011865084655}]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "apro_mar = Aproiri(data,0.05,0.05)\n",
    "L_union, L_union_support = apro_mar.apriori()\n",
    "L_union_support[:5] # print  before five "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{\"frozenset({'mineral water'})-->frozenset({'spaghetti'})(support:0.05972536995067324)\": 0.2505592841163311},\n",
       " {\"frozenset({'mineral water'})-->frozenset({'eggs'})(support:0.05092654312758299)\": 0.21364653243847875},\n",
       " {\"frozenset({'mineral water'})-->frozenset({'chocolate'})(support:0.05265964538061592)\": 0.220917225950783},\n",
       " {\"frozenset({'spaghetti'})-->frozenset({'mineral water'})(support:0.05972536995067324)\": 0.3430321592649311},\n",
       " {\"frozenset({'eggs'})-->frozenset({'mineral water'})(support:0.05092654312758299)\": 0.28338278931750743},\n",
       " {\"frozenset({'chocolate'})-->frozenset({'mineral water'})(support:0.05265964538061592)\": 0.3213995117982099}]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rules = apro_mar.association_rules(L_union,L_union_support)\n",
    "rules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using FP Growth Algorithm to calculate the frequent itemset of the data in file 'FPGrowth.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 475 µs, sys: 1.04 ms, total: 1.51 ms\n",
      "Wall time: 1.23 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['I1', 'I2', 'I5'],\n",
       " ['I2', 'I4'],\n",
       " ['I2', 'I3', 'I6'],\n",
       " ['I1', 'I2', 'I4'],\n",
       " ['I1', 'I3'],\n",
       " ['I2', 'I3'],\n",
       " ['I1', 'I3'],\n",
       " ['I1', 'I2', 'I3', 'I5'],\n",
       " ['I1', 'I2', 'I3']]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "from pathlib import Path\n",
    "f_fp = Path('FPGrowth.csv')\n",
    "dataSet = [list(line.split(',')) for line in f_fp.read_text().replace(' ','').split('\\n')]\n",
    "# with open('FPGrowth.csv', 'r') as f:\n",
    "#     data = [list(map(lambda item: item.strip(), trans.split(','))) for trans in f] # use map + lambda\n",
    "# data\n",
    "dataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   pyramid   9\n",
      "     eye   13\n"
     ]
    }
   ],
   "source": [
    "class treeNode:\n",
    "    def __init__(self, nameValue, numOccur, parentNode):\n",
    "        self.name = nameValue\n",
    "        self.count = numOccur\n",
    "        self.nodeLink = None\n",
    "        self.parent = parentNode      #needs to be updated\n",
    "        self.children = {} \n",
    "#increments the count variable with a given amount    \n",
    "    def inc(self, numOccur):\n",
    "        self.count += numOccur\n",
    "#display tree in text. Useful for debugging        \n",
    "    def disp(self, ind=1):\n",
    "        print ('  '*ind, self.name, ' ', self.count) # The blank space * ind\n",
    "        for child in self.children.values():\n",
    "            child.disp(ind+1)\n",
    "rootNode = treeNode('pyramid',9,None)\n",
    "rootNode.children['eye'] = treeNode('eye',13,None)\n",
    "rootNode.disp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createTree(dataSet, minSup=1): #create FP-tree from dataset but don't mine\n",
    "    headerTable = {}\n",
    "    #go over dataSet twice\n",
    "    for trans in dataSet:#first pass counts frequency of occurance\n",
    "        for item in trans:\n",
    "            headerTable[item] = headerTable.get(item, 0) + dataSet[trans]\n",
    "    for k in list(headerTable):  #remove items not meeting minSup\n",
    "        if headerTable[k] < minSup: \n",
    "            del(headerTable[k])\n",
    "    freqItemSet = set(headerTable.keys())\n",
    "#     print('freqItemSet: ',freqItemSet)\n",
    "    if len(freqItemSet) == 0: return None, None  #if no items meet min support -->get out\n",
    "    for k in headerTable:\n",
    "        headerTable[k] = [headerTable[k], None] #reformat headerTable to use Node link \n",
    "#     print('headerTable: ',headerTable)\n",
    "    retTree = treeNode('Null Set', 1, None) #create tree\n",
    "    for tranSet, count in dataSet.items():  #go through dataset 2nd time\n",
    "        localD = {}\n",
    "        for item in tranSet:  #put transaction items in order\n",
    "            if item in freqItemSet:\n",
    "                localD[item] = headerTable[item][0]\n",
    "        if len(localD) > 0:\n",
    "            orderedItems = [v[0] for v in sorted(localD.items(), key=lambda p: p[1], reverse=True)] # sorted by big to small\n",
    "            updateTree(orderedItems, retTree, headerTable, count)#populate tree with ordered freq itemset\n",
    "    return retTree, headerTable #return tree and header table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def updateTree(items, inTree, headerTable, count):\n",
    "    if items[0] in inTree.children:#check if orderedItems[0] in retTree.children\n",
    "        inTree.children[items[0]].inc(count) #incrament count\n",
    "    else:   #add items[0] to inTree.children\n",
    "        inTree.children[items[0]] = treeNode(items[0], count, inTree)\n",
    "        if headerTable[items[0]][1] == None: #update header table \n",
    "            headerTable[items[0]][1] = inTree.children[items[0]]\n",
    "        else:\n",
    "            updateHeader(headerTable[items[0]][1], inTree.children[items[0]])\n",
    "    if len(items) > 1:#call updateTree() with remaining ordered items\n",
    "        updateTree(items[1::], inTree.children[items[0]], headerTable, count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def updateHeader(nodeToTest, targetNode):   #this version does not use recursion\n",
    "    while (nodeToTest.nodeLink != None):    #Do not use recursion to traverse a linked list!\n",
    "        nodeToTest = nodeToTest.nodeLink\n",
    "    nodeToTest.nodeLink = targetNode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{frozenset({'I1', 'I2', 'I5'}): 1,\n",
       " frozenset({'I2', 'I4'}): 1,\n",
       " frozenset({'I2', 'I3', 'I6'}): 1,\n",
       " frozenset({'I1', 'I2', 'I4'}): 1,\n",
       " frozenset({'I1', 'I3'}): 2,\n",
       " frozenset({'I2', 'I3'}): 1,\n",
       " frozenset({'I1', 'I2', 'I3', 'I5'}): 1,\n",
       " frozenset({'I1', 'I2', 'I3'}): 1}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def createInitSet(dataSet):\n",
    "    retDict = {}\n",
    "    for trans in dataSet:\n",
    "        if frozenset(trans) in retDict:\n",
    "            retDict[frozenset(trans)] += 1\n",
    "        else:\n",
    "            retDict[frozenset(trans)] = 1\n",
    "    return retDict\n",
    "initSet = createInitSet(dataSet)\n",
    "initSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Null Set   1\n",
      "     I2   7\n",
      "       I1   4\n",
      "         I5   1\n",
      "         I4   1\n",
      "         I3   2\n",
      "           I5   1\n",
      "       I4   1\n",
      "       I3   2\n",
      "     I3   2\n",
      "       I1   2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'I5': [2, <__main__.treeNode at 0x7f3ed4739820>],\n",
       " 'I2': [7, <__main__.treeNode at 0x7f3ed4739b20>],\n",
       " 'I1': [6, <__main__.treeNode at 0x7f3ed4739a60>],\n",
       " 'I4': [2, <__main__.treeNode at 0x7f3ed4739af0>],\n",
       " 'I3': [6, <__main__.treeNode at 0x7f3ed4739160>]}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myFPtree, myHeaderTab = createTree(initSet, 2)\n",
    "myFPtree.disp()\n",
    "myHeaderTab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ascendTree(leafNode, prefixPath): #ascends from leaf node to root\n",
    "    if leafNode.parent != None:\n",
    "        prefixPath.append(leafNode.name)\n",
    "        ascendTree(leafNode.parent, prefixPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{frozenset({'I2'}): 4, frozenset({'I3'}): 2}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def findPrefixPath(basePat, treeNode): #treeNode comes from header table\n",
    "    condPats = {}\n",
    "    while treeNode != None:\n",
    "        prefixPath = []\n",
    "        ascendTree(treeNode, prefixPath)\n",
    "        if len(prefixPath) > 1: \n",
    "            condPats[frozenset(prefixPath[1:])] = treeNode.count\n",
    "        treeNode = treeNode.nodeLink\n",
    "    return condPats\n",
    "findPrefixPath('I1', myHeaderTab['I1'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'I5'},\n",
       " {'I2', 'I5'},\n",
       " {'I1', 'I5'},\n",
       " {'I1', 'I2', 'I5'},\n",
       " {'I4'},\n",
       " {'I2', 'I4'},\n",
       " {'I1'},\n",
       " {'I1', 'I3'},\n",
       " {'I1', 'I2'},\n",
       " {'I3'},\n",
       " {'I1', 'I3'},\n",
       " {'I1', 'I2', 'I3'},\n",
       " {'I2', 'I3'},\n",
       " {'I2'}]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def mineFPtree(inTree, headerTable, minSup, preFix, freqItemList):\n",
    "    orderedItems = [v[0] for v in sorted(headerTable.items(), key=lambda p:p[1][0])] # big to small\n",
    "    for item in orderedItems: \n",
    "        newFreqSet = preFix.copy() # The next level must be the same as the previous level --requires copy\n",
    "        newFreqSet.add(item)\n",
    "        freqItemList.append(newFreqSet)\n",
    "        condPattBases = findPrefixPath(item, headerTable[item][1]) # Conditional pattern base\n",
    "        myCondTree, myConHead = createTree(condPattBases, minSup)  # Conditional FP Tree\n",
    "        if myConHead != None:\n",
    "            mineFPtree(myCondTree, myConHead, minSup, newFreqSet, freqItemList) # Recursive mining\n",
    "freqItemList = []          \n",
    "mineFPtree(myFPtree, myHeaderTab, 2, set([]), freqItemList)\n",
    "freqItemList"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using FP Growth Algorithm to calculate the frequent itemset of the data in file 'Market_Basket_Optimisation.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'gluten free bar'},\n",
       " {'extra dark chocolate', 'gluten free bar'},\n",
       " {'extra dark chocolate', 'gluten free bar', 'mineral water'},\n",
       " {'gluten free bar', 'mushroom cream sauce'},\n",
       " {'gluten free bar', 'mushroom cream sauce', 'salmon'},\n",
       " {'gluten free bar', 'honey', 'mushroom cream sauce'},\n",
       " {'gluten free bar', 'honey', 'mushroom cream sauce', 'salmon'},\n",
       " {'frozen vegetables', 'gluten free bar', 'mushroom cream sauce'},\n",
       " {'frozen vegetables', 'gluten free bar', 'mushroom cream sauce', 'salmon'},\n",
       " {'frozen vegetables', 'gluten free bar', 'honey', 'mushroom cream sauce'}]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fMar = Path('Market_Basket_Optimisation.csv')\n",
    "dataSet = [list(line.split(',')) for line in fMar.read_text().strip().split('\\n')]\n",
    "# print(dataSet[:5])\n",
    "initSet = createInitSet(dataSet)\n",
    "myFPtree, myHeaderTab = createTree(initSet, 50)\n",
    "freqItemList = []          \n",
    "mineFPtree(myFPtree, myHeaderTab, 2, set([]), freqItemList)\n",
    "freqItemList[:10] # 50 freq / before 10"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
