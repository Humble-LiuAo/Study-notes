[toc]

### 概率分类法概述

概率分类法是一种基于概率理论的分类方法，它通过计算样本数据的概率来确定样本所属的类别。具体来说，概率分类法的基本思想是将样本数据映射到一个概率空间中，然后根据概率空间中每个类别的概率来判断样本所属的类别。

### 1. 朴素贝叶斯分类器(Naïve Bayesian Classifier)

朴素贝叶斯分类器的基本思想是，对于一个待分类的样本，通过计算该样本在各个特征上的条件概率，来确定该样本属于哪个类别。具体来说，朴素贝叶斯分类器假设各个特征之间相互独立，因此可以将样本在各个特征上的条件概率相乘，得到该样本属于每个类别的后验概率，从而确定该样本所属的类别。

朴素贝叶斯分类器的算法流程如下：

1. 对训练集进行特征提取，并计算每个特征在每个类别下的条件概率。
2. 对于一个待分类的样本，计算该样本在各个特征上的条件概率，并将其相乘。
3. 根据贝叶斯定理，计算该样本在每个类别下的后验概率。
4. 将该样本归为后验概率最大的类别。

朴素贝叶斯分类器的优点是简单、快速，适用于高维度的数据，并且对缺失数据也能够进行处理。但是，它的假设条件比较苛刻，需要满足各个特征之间相互独立的条件，因此在某些实际应用中可能表现不佳。

#### 本质

1. **在统计资料的基础上，依据某些特征，计算各个类别的概率，从而实现分类**
2. 训练计算概率，测试查表，即：![image-20211106154430622](https://gitee.com/humble_ao/Image/raw/master/image-20211106154430622.png)

### 2. 高斯概率密度估计 

1. 假设X的概率分布的具体形式==P(X|C)==，在这个具体形式中有一些待定参数
2. 用==极大似然法==构造优化目标函数
3. 解 2 中的优化问题，获得待求参数

* ==极大似然法==

1. **利用已知的样本结果信息，反推最具有可能（最大概率）导致这些样本结果出现的模型参数值！**（极大似然估计只是一种粗略的[数学期望](https://baike.baidu.com/item/数学期望)，要知道它的误差大小还要做区间估计。）

2. 求极大似然函数估计值的一般步骤：

   （1） 写出[似然函数](https://baike.baidu.com/item/似然函数)；

   （2） 对似然函数取对数，并整理；

   （3） 求[导数](https://baike.baidu.com/item/导数) ；

   （4） 解似然方程 。

#### 高斯混合模型(Gaussian Mixture Model)

**本质**：两个或者多个高斯分布的线性叠加（非凸函数无法求全局极值，只能求局部极值）

#### EM算法(Expectation-Maximization)

* 算法原理

![image-20211107135817914](https://gitee.com/humble_ao/Image/raw/master/image-20211107135817914.png)

![image-20211107135824994](https://gitee.com/humble_ao/Image/raw/master/image-20211107135824994.png)

#### EM算法应用（K均值 K-means Clustering 和高斯混合模型）

![image-20211107135904223](https://gitee.com/humble_ao/Image/raw/master/image-20211107135904223.png)

![image-20211107135916511](https://gitee.com/humble_ao/Image/raw/master/image-20211107135916511.png)

![image-20211107135938366](https://gitee.com/humble_ao/Image/raw/master/image-20211107135938366.png)
